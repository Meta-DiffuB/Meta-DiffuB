{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85793800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('.')\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc34a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import socket\n",
    "import blobfile as bf\n",
    "import io\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import functools\n",
    "import gc\n",
    "from functools import partial\n",
    "\n",
    "from diffuseq.utils import logger\n",
    "from diffuseq.utils.nn import (\n",
    "    SiLU,\n",
    "    linear,\n",
    "    timestep_embedding,\n",
    "    mean_flat,\n",
    "    update_ema\n",
    ")\n",
    "from diffuseq.utils.fp16_util import (\n",
    "    make_master_params,\n",
    "    master_params_to_model_params,\n",
    "    model_grads_to_master_grads,\n",
    "    unflatten_master_params,\n",
    "    zero_grad,\n",
    ")\n",
    "\n",
    "from transformers import set_seed, AutoTokenizer, PreTrainedTokenizerFast, AutoConfig\n",
    "from transformers.models.bert.modeling_bert import BertEncoder, BertModel\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.parallel.distributed import DistributedDataParallel as DDP\n",
    "\n",
    "import psutil\n",
    "import datasets\n",
    "from datasets import Dataset as Dataset2\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "from itertools import chain,groupby\n",
    "\n",
    "# from torchmetrics.text.rouge import ROUGEScore\n",
    "# from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "# import nltk\n",
    "# from bert_score import score\n",
    "\n",
    "import subprocess as sp\n",
    "\n",
    "# import requests\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdd33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPUNumber = 0\n",
    "\n",
    "seed = 102\n",
    "\n",
    "learning_rate = 1e-4\n",
    "hidden_t_dim = 128\n",
    "hidden_dim = 128\n",
    "dropout = 0.1\n",
    "weight_decay = 0.0\n",
    "  \n",
    "diffusion_steps = 2000\n",
    "ema_rate = 0.9999\n",
    "schedule_sampler_name = 'lossaware'\n",
    "noise_schedule = 'sqrt'\n",
    "timestep_respacing = ''\n",
    "\n",
    "dataset = 'Wiki'\n",
    "data_dir = f'./datasets/{dataset}'\n",
    "vocab = 'bert'\n",
    "seq_len = 128\n",
    "\n",
    "use_plm_init = 'no'\n",
    "\n",
    "config_name = 'bert-base-uncased'\n",
    "\n",
    "diffusion_ver = 'metaBeta_ver'\n",
    "checkpoint_path = f'checkpoint/{dataset}/{diffusion_ver}'\n",
    "if not os.path.isdir(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "\n",
    "use_fp16 = False\n",
    "gradient_clipping = -1.0 \n",
    "learn_sigma = False\n",
    "use_kl = False\n",
    "predict_xstart = True\n",
    "rescale_timesteps = True\n",
    "rescale_learned_sigmas = False\n",
    "sigma_small = False\n",
    "emb_scale_factor = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d3daa",
   "metadata": {},
   "source": [
    "## Funciton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c6a249",
   "metadata": {},
   "source": [
    "### dist_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc57446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_dist():\n",
    "    \"\"\"\n",
    "    Setup a distributed process group.\n",
    "    \"\"\"\n",
    "    if dist.is_initialized():\n",
    "        return\n",
    "\n",
    "    backend = \"gloo\" if not th.cuda.is_available() else \"nccl\"\n",
    "\n",
    "    if backend == \"gloo\":\n",
    "        hostname = \"localhost\"\n",
    "    else:\n",
    "        hostname = socket.gethostbyname(socket.getfqdn())\n",
    "\n",
    "    if os.environ.get(\"LOCAL_RANK\") is None:\n",
    "        os.environ[\"MASTER_ADDR\"] = hostname\n",
    "        os.environ[\"RANK\"] = str(0)\n",
    "        os.environ[\"WORLD_SIZE\"] = str(1)\n",
    "        port = _find_free_port()\n",
    "        os.environ[\"MASTER_PORT\"] = str(port)\n",
    "        os.environ['LOCAL_RANK'] = str(GPUNumber)\n",
    "    \n",
    "    dist.init_process_group(backend=backend, init_method=\"env://\")\n",
    "    \n",
    "def dev():\n",
    "    \"\"\"\n",
    "    Get the device to use for torch.distributed.\n",
    "    \"\"\"\n",
    "    if th.cuda.is_available():\n",
    "        return th.device(f\"cuda:{os.environ['LOCAL_RANK']}\")\n",
    "    return th.device(\"cpu\")\n",
    "\n",
    "\n",
    "def load_state_dict(path, **kwargs):\n",
    "    \"\"\"\n",
    "    Load a PyTorch file.\n",
    "    \"\"\"\n",
    "    with bf.BlobFile(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    return th.load(io.BytesIO(data), **kwargs)\n",
    "\n",
    "\n",
    "def sync_params(params):\n",
    "    \"\"\"\n",
    "    Synchronize a sequence of Tensors across ranks from rank 0.\n",
    "    \"\"\"\n",
    "    for p in params:\n",
    "        with th.no_grad():\n",
    "            dist.broadcast(p, 0)\n",
    "\n",
    "\n",
    "def _find_free_port():\n",
    "    try:\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        s.bind((\"\", 0))\n",
    "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        return s.getsockname()[1]\n",
    "    finally:\n",
    "        s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3919530",
   "metadata": {},
   "source": [
    "### basic_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264e867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myTokenizer():\n",
    "    \"\"\"\n",
    "    Load tokenizer from bert config or defined BPE vocab dict\n",
    "    \"\"\"\n",
    "    ################################################\n",
    "    ### You can custome your own tokenizer here. ###\n",
    "    ################################################\n",
    "    def __init__(self, config_name, checkpoint_path, vocab):\n",
    "        if vocab == 'bert':\n",
    "            tokenizer = AutoTokenizer.from_pretrained(config_name)\n",
    "            self.tokenizer = tokenizer\n",
    "            self.sep_token_id = tokenizer.sep_token_id\n",
    "            self.pad_token_id = tokenizer.pad_token_id\n",
    "            # save\n",
    "            tokenizer.save_pretrained(checkpoint_path)\n",
    "        else: \n",
    "            # load vocab from the path\n",
    "            print('#'*30, 'load vocab from', vocab)\n",
    "            vocab_dict = {'[START]': 0, '[END]': 1, '[UNK]':2, '[PAD]':3}\n",
    "            with open(vocab, 'r', encoding='utf-8') as f:\n",
    "                for row in f:\n",
    "                    vocab_dict[row.strip().split(' ')[0]] = len(vocab_dict)\n",
    "            self.tokenizer = vocab_dict\n",
    "            self.rev_tokenizer = {v: k for k, v in vocab_dict.items()}\n",
    "            self.sep_token_id = vocab_dict['[END]']\n",
    "            self.pad_token_id = vocab_dict['[PAD]']\n",
    "            # save\n",
    "            if int(os.environ['LOCAL_RANK']) == 0:\n",
    "                path_save_vocab = f'{checkpoint_path}/vocab.json'\n",
    "                with open(path_save_vocab, 'w') as f:\n",
    "                    json.dump(vocab_dict, f)\n",
    "                \n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "    \n",
    "    def encode_token(self, sentences):\n",
    "        if isinstance(self.tokenizer, dict):\n",
    "            input_ids = [[0] + [self.tokenizer.get(x, self.tokenizer['[UNK]']) for x in seq.split()] + [1] for seq in sentences]\n",
    "        elif isinstance(self.tokenizer, PreTrainedTokenizerFast):\n",
    "            # special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n",
    "            input_ids = self.tokenizer(sentences, add_special_tokens=True)['input_ids']\n",
    "        else:\n",
    "            assert False, \"invalid type of vocab_dict\"\n",
    "        return input_ids\n",
    "        \n",
    "    def decode_token(self, seq):\n",
    "        if isinstance(self.tokenizer, dict):\n",
    "            seq = seq.squeeze(-1).tolist()\n",
    "            while len(seq)>0 and seq[-1] == self.pad_token_id:\n",
    "                seq.pop()\n",
    "            tokens = \" \".join([self.rev_tokenizer[x] for x in seq]).replace('__ ', '').replace('@@ ', '')\n",
    "        elif isinstance(self.tokenizer, PreTrainedTokenizerFast):\n",
    "            seq = seq.squeeze(-1).tolist()\n",
    "            while len(seq)>0 and seq[-1] == self.pad_token_id:\n",
    "                seq.pop()\n",
    "            tokens = self.tokenizer.decode(seq)\n",
    "        else:\n",
    "            assert False, \"invalid type of vocab_dict\"\n",
    "        return tokens\n",
    "    \n",
    "def load_tokenizer(config_name, checkpoint_path, vocab):\n",
    "    tokenizer = myTokenizer(config_name, checkpoint_path, vocab)\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "    return tokenizer, vocab_size\n",
    "\n",
    "def load_model_emb(vocab_size, hidden_dim, checkpoint_path):\n",
    "    ### random emb or pre-defined embedding like glove embedding. You can custome your own init here.\n",
    "    model = th.nn.Embedding(vocab_size, hidden_dim)\n",
    "    path_save = '{}/random_emb.torch'.format(checkpoint_path)\n",
    "    path_save_ind = path_save + \".done\"\n",
    "    if int(os.environ['LOCAL_RANK']) == GPUNumber:\n",
    "        if os.path.exists(path_save):\n",
    "            # print('reload the random embeddings', model)\n",
    "            model.load_state_dict(th.load(path_save))\n",
    "        else:\n",
    "            print('initializing the random embeddings', model)\n",
    "            # random Gaussian embeddings as well as pre-trained word embedding (from diffusion-LM paper)\n",
    "            th.nn.init.normal_(model.weight)\n",
    "            th.save(model.state_dict(), path_save)\n",
    "            os.sync() # It is used to force write of everything to disk.\n",
    "            with open(path_save_ind, \"x\") as _:\n",
    "                pass\n",
    "    else:\n",
    "        while not os.path.exists(path_save_ind):\n",
    "            time.sleep(1)\n",
    "        # print('reload the random embeddings', model)\n",
    "        model.load_state_dict(th.load(path_save))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_model_and_diffusion(\n",
    "    hidden_t_dim,\n",
    "    hidden_dim,\n",
    "    vocab_size,\n",
    "    config_name,\n",
    "    use_plm_init,\n",
    "    dropout,\n",
    "    diffusion_steps,\n",
    "    betas,\n",
    "    # noise_schedule,\n",
    "    learn_sigma,\n",
    "    timestep_respacing,\n",
    "    predict_xstart,\n",
    "    rescale_timesteps,\n",
    "    sigma_small,\n",
    "    rescale_learned_sigmas,\n",
    "    use_kl,\n",
    "    notes,\n",
    "    **kwargs,\n",
    "):\n",
    "    model = TransformerNetModel(\n",
    "        input_dims=hidden_dim,\n",
    "        output_dims=(hidden_dim if not learn_sigma else hidden_dim*2),\n",
    "        hidden_t_dim=hidden_t_dim,\n",
    "        dropout=dropout,\n",
    "        config_name=config_name,\n",
    "        vocab_size=vocab_size,\n",
    "        init_pretrained=use_plm_init\n",
    "    )\n",
    "\n",
    "    if not timestep_respacing:\n",
    "        timestep_respacing = [diffusion_steps]\n",
    "\n",
    "    diffusion = SpacedDiffusion(\n",
    "        use_timesteps=space_timesteps(diffusion_steps, timestep_respacing),\n",
    "        betas=betas,\n",
    "        rescale_timesteps=rescale_timesteps,\n",
    "        predict_xstart=predict_xstart,\n",
    "        learn_sigmas = learn_sigma,\n",
    "        sigma_small = sigma_small,\n",
    "        use_kl = use_kl,\n",
    "        rescale_learned_sigmas=rescale_learned_sigmas\n",
    "    )\n",
    "\n",
    "    return model, diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fbd534",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c7085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_text(\n",
    "    batch_size, \n",
    "    seq_len, \n",
    "    dataset, \n",
    "    data_dir,\n",
    "    deterministic=False,  \n",
    "    model_emb=None,\n",
    "    split='train', \n",
    "    loaded_vocab=None,\n",
    "    loop=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    For a dataset, create a generator over (seqs, kwargs) pairs.\n",
    "\n",
    "    Each seq is an (bsz, len, h) float tensor, and the kwargs dict contains zero or\n",
    "    more keys, each of which map to a batched Tensor of their own.\n",
    "    The kwargs dict can be used for some meta information.\n",
    "\n",
    "    :param batch_size: the batch size of each returned pair.\n",
    "    :param seq_len: the max sequence length (one-side).\n",
    "    :param deterministic: if True, yield results in a deterministic order.\n",
    "    :param data_args: including dataset directory, num of dataset, basic settings, etc.\n",
    "    :param model_emb: loaded word embeddings.\n",
    "    :param loaded_vocab: loaded word vocabs.\n",
    "    :param loop: loop to get batch data or not.\n",
    "    \"\"\"\n",
    "\n",
    "    print('#'*30, '\\nLoading text data...')\n",
    "\n",
    "    training_data = get_corpus(dataset, data_dir, seq_len, split=split, loaded_vocab=loaded_vocab)\n",
    "    \n",
    "    dataset = TextDataset(\n",
    "        training_data,\n",
    "        model_emb=model_emb\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=not deterministic,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    if loop:\n",
    "        return infinite_loader(data_loader)\n",
    "    else:\n",
    "        # print(data_loader)\n",
    "        return iter(data_loader)\n",
    "\n",
    "def infinite_loader(data_loader):\n",
    "    while True:\n",
    "        yield from data_loader\n",
    "\n",
    "def helper_tokenize(sentence_lst, vocab_dict, seq_len):\n",
    "    # Process.memory_info is expressed in bytes, so convert to megabytes\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "    raw_datasets = Dataset2.from_dict(sentence_lst)\n",
    "    print(raw_datasets)\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        input_id_x = vocab_dict.encode_token(examples['src'])\n",
    "        input_id_y = vocab_dict.encode_token(examples['trg'])\n",
    "        result_dict = {'input_id_x': input_id_x, 'input_id_y': input_id_y}\n",
    "\n",
    "        return result_dict\n",
    "\n",
    "    # Tokenize the data x and y\n",
    "    tokenized_datasets = raw_datasets.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        num_proc=4,\n",
    "        remove_columns=['src', 'trg'],\n",
    "        load_from_cache_file=True,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "    print('### tokenized_datasets', tokenized_datasets)\n",
    "    print('### tokenized_datasets...example', tokenized_datasets['input_id_x'][0])\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "    def merge_and_mask(group_lst):\n",
    "        lst = []\n",
    "        mask = []\n",
    "        for i in range(len(group_lst['input_id_x'])):\n",
    "            end_token = group_lst['input_id_x'][i][-1]\n",
    "            src = group_lst['input_id_x'][i][:-1]\n",
    "            trg = group_lst['input_id_y'][i][:-1]\n",
    "            while len(src) + len(trg) > seq_len - 3:\n",
    "                if len(src)>len(trg):\n",
    "                    src.pop()\n",
    "                elif len(src)<len(trg):\n",
    "                    trg.pop()\n",
    "                else:\n",
    "                    src.pop()\n",
    "                    trg.pop()\n",
    "            src.append(end_token)\n",
    "            trg.append(end_token)\n",
    "            \n",
    "            lst.append(src + [vocab_dict.sep_token_id] + trg)\n",
    "            mask.append([0]*(len(src)+1))\n",
    "        group_lst['input_ids'] = lst\n",
    "        group_lst['input_mask'] = mask\n",
    "        return group_lst\n",
    "    \n",
    "    # Merge data x+[sep]+y\n",
    "    # Mask  data 0(x+[sep])\n",
    "    tokenized_datasets = tokenized_datasets.map(\n",
    "        merge_and_mask,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        desc=f\"merge and mask\",\n",
    "    )\n",
    "    \n",
    "    def pad_function(group_lst):\n",
    "        max_length = seq_len\n",
    "        group_lst['input_ids'] = _collate_batch_helper(group_lst['input_ids'], vocab_dict.pad_token_id, max_length)\n",
    "        group_lst['input_mask'] = _collate_batch_helper(group_lst['input_mask'], 1, max_length)\n",
    "        return group_lst\n",
    "\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "    # trim data and add padding\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        pad_function,\n",
    "        batched=True,\n",
    "        num_proc=1,\n",
    "        desc=f\"padding\",\n",
    "    )\n",
    "\n",
    "    print(lm_datasets, 'padded dataset')\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "    raw_datasets = datasets.DatasetDict()\n",
    "    raw_datasets['train'] = lm_datasets\n",
    "    print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")\n",
    "    return raw_datasets\n",
    "\n",
    "\n",
    "def get_corpus(dataset, data_dir, seq_len, split='train', loaded_vocab=None):\n",
    "\n",
    "    print('#'*30, '\\nLoading dataset {} from {}...'.format(dataset, data_dir))\n",
    "\n",
    "    sentence_lst = {'src':[], 'trg': []}\n",
    "    \n",
    "    if split == 'train':\n",
    "        print('### Loading form the TRAIN set...')\n",
    "        path = f'{data_dir}/train.jsonl'\n",
    "    elif split == 'valid':\n",
    "        print('### Loading form the VALID set...')\n",
    "        path = f'{data_dir}/valid.jsonl'\n",
    "    elif split == 'test':\n",
    "        print('### Loading form the TEST set...')\n",
    "        path = f'{data_dir}/test.jsonl'\n",
    "    else:\n",
    "        assert False, \"invalid split for dataset\"\n",
    "\n",
    "    with open(path, 'r') as f_reader:\n",
    "        for row in f_reader:\n",
    "            sentence_lst['src'].append(json.loads(row)['src'].strip())\n",
    "            sentence_lst['trg'].append(json.loads(row)['trg'].strip())\n",
    "\n",
    "    print('### Data samples...\\n', sentence_lst['src'][:2], sentence_lst['trg'][:2])\n",
    "        \n",
    "    # get tokenizer.\n",
    "    vocab_dict = loaded_vocab\n",
    "\n",
    "    train_dataset = helper_tokenize(sentence_lst, vocab_dict, seq_len)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_datasets, model_emb=None):\n",
    "        super().__init__()\n",
    "        self.text_datasets = text_datasets\n",
    "        self.length = len(self.text_datasets['train'])\n",
    "        self.model_emb = model_emb\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with th.no_grad():\n",
    "            input_ids = self.text_datasets['train'][idx]['input_ids']\n",
    "            hidden_state = self.model_emb(th.tensor(input_ids).to(dev()))\n",
    "            \n",
    "            arr = np.array(hidden_state.cpu(), dtype=np.float32)\n",
    "\n",
    "            out_kwargs = {}\n",
    "            out_kwargs['input_ids'] = np.array(self.text_datasets['train'][idx]['input_ids'])\n",
    "            out_kwargs['input_mask'] = np.array(self.text_datasets['train'][idx]['input_mask'])\n",
    "\n",
    "            return arr, out_kwargs\n",
    "\n",
    "def _collate_batch_helper(examples, pad_token_id, max_length, return_mask=False):\n",
    "    result = th.full([len(examples), max_length], pad_token_id, dtype=th.int64).tolist()\n",
    "    mask_ = th.full([len(examples), max_length], pad_token_id, dtype=th.int64).tolist()\n",
    "    for i, example in enumerate(examples):\n",
    "        curr_len = min(len(example), max_length)\n",
    "        result[i][:curr_len] = example[:curr_len]\n",
    "        mask_[i][:curr_len] = [1] * curr_len\n",
    "    if return_mask:\n",
    "        return result, mask_\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adea7e",
   "metadata": {},
   "source": [
    "### gaussian_diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca08b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion:\n",
    "    \"\"\"\n",
    "    Utilities for training and sampling diffusion models.\n",
    "\n",
    "    Ported directly from here, and then adapted over time to further experimentation.\n",
    "    https://github.com/hojonathanho/diffusion/blob/1e0dceb3b3495bbe19116a5e1b3596cd0706c543/diffusion_tf/diffusion_utils_2.py#L42\n",
    "\n",
    "    :param betas: a 1-D numpy array of betas for each diffusion timestep,\n",
    "                  starting at T and going to 1.\n",
    "    :param predict_xstart: the model outputs to predict x_0, else to predict eps.\n",
    "    :param learn_sigmas: the model outputs to predict sigma or not. Default: False\n",
    "    :param rescale_learned_sigmas, sigma_small: details setting of learned sigmas\n",
    "    :param rescale_timesteps: if True, pass floating point timesteps into the\n",
    "                              model so that they are always scaled like in the\n",
    "                              original paper (0 to 1000).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        betas,\n",
    "        predict_xstart,\n",
    "        rescale_learned_sigmas,\n",
    "        learn_sigmas,\n",
    "        sigma_small,\n",
    "        use_kl,\n",
    "        rescale_timesteps=False,\n",
    "    ):\n",
    "        self.rescale_timesteps = rescale_timesteps\n",
    "        self.predict_xstart = predict_xstart\n",
    "        self.rescale_learned_sigmas = rescale_learned_sigmas\n",
    "        self.learn_sigmas = learn_sigmas\n",
    "        self.sigma_small = sigma_small\n",
    "        self.use_kl = use_kl\n",
    "\n",
    "        betas = np.array(betas, dtype=np.float64)\n",
    "        self.betas = betas\n",
    "        assert (betas > 0).all() and (betas <= 1).all()\n",
    "\n",
    "        self.num_timesteps = int(betas.shape[1])\n",
    "\n",
    "        alphas = 1.0 - betas\n",
    "        self.alphas_cumprod = np.cumprod(alphas, axis=1)\n",
    "        self.alphas_cumprod_prev = np.insert(self.alphas_cumprod, 0, 1.0, axis=1)[:, :-1]\n",
    "        \n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.sqrt_alphas_cumprod = np.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.log_one_minus_alphas_cumprod = np.log(1.0 - self.alphas_cumprod)\n",
    "        self.sqrt_recip_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod)\n",
    "        self.sqrt_recipm1_alphas_cumprod = np.sqrt(1.0 / self.alphas_cumprod - 1)\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        self.posterior_variance = (\n",
    "            betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        \n",
    "        # log calculation clipped because the posterior variance is 0 at the\n",
    "        # beginning of the diffusion chain.\n",
    "        self.posterior_log_variance_clipped = np.log(\n",
    "            np.insert(self.posterior_variance, 1, self.posterior_variance[:, 1], axis=1)[:, 1:]\n",
    "        )\n",
    "        self.posterior_mean_coef1 = (\n",
    "            betas * np.sqrt(self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        self.posterior_mean_coef2 = (\n",
    "            (1.0 - self.alphas_cumprod_prev)\n",
    "            * np.sqrt(alphas)\n",
    "            / (1.0 - self.alphas_cumprod)\n",
    "        )\n",
    "        \n",
    "        self.mapping_func = None # implement in train main()\n",
    "        self.add_mask_noise = False # TODO\n",
    "        \n",
    "\n",
    "    def training_losses(self, model, *args, **kwargs):\n",
    "        self.model = model\n",
    "        return self.training_losses_seq2seq(model, *args, **kwargs)\n",
    "\n",
    "    def _predict_xstart_from_eps(self, x_t, t, offsets, eps):\n",
    "        assert x_t.shape == eps.shape\n",
    "        return (\n",
    "            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape, offsets) * x_t\n",
    "            - _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape, offsets) * eps\n",
    "        )\n",
    "\n",
    "    def _predict_eps_from_xstart(self, x_t, t, pred_xstart, offsets):\n",
    "        return (\n",
    "            _extract_into_tensor(self.sqrt_recip_alphas_cumprod, t, x_t.shape, offsets) * x_t\n",
    "            - pred_xstart\n",
    "        ) / _extract_into_tensor(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape, offsets)\n",
    "\n",
    "    def _scale_timesteps(self, t):\n",
    "        if self.rescale_timesteps:\n",
    "            return t.float() * (1000.0 / self.num_timesteps)\n",
    "        return t\n",
    "\n",
    "    def q_mean_variance(self, x_start, t, offsets):\n",
    "        \"\"\"\n",
    "        Get the distribution q(x_t | x_0).\n",
    "\n",
    "        :param x_start: the [N x C x ...] tensor of noiseless inputs.\n",
    "        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n",
    "        :return: A tuple (mean, variance, log_variance), all of x_start's shape.\n",
    "        \"\"\"\n",
    "        mean = (\n",
    "            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape, offsets) * x_start\n",
    "        )\n",
    "        variance = _extract_into_tensor(1.0 - self.alphas_cumprod, t, x_start.shape, offsets)\n",
    "        log_variance = _extract_into_tensor(\n",
    "            self.log_one_minus_alphas_cumprod, t, x_start.shape, offsets\n",
    "        )\n",
    "        return mean, variance, log_variance\n",
    "\n",
    "    def q_sample(self, x_start, t, offsets, noise=None, mask=None):\n",
    "        \"\"\"\n",
    "        Diffuse the data for a given number of diffusion steps.\n",
    "\n",
    "        In other words, sample from q(x_t | x_0).\n",
    "\n",
    "        :param x_start: the initial data batch.\n",
    "        :param t: the number of diffusion steps (minus 1). Here, 0 means one step.\n",
    "        :param noise: if specified, the split-out normal noise.\n",
    "        :param mask: anchoring masked position\n",
    "        :return: A noisy version of x_start.\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = th.randn_like(x_start)\n",
    "\n",
    "        assert noise.shape == x_start.shape\n",
    "        \n",
    "        x_t = (\n",
    "            _extract_into_tensor(self.sqrt_alphas_cumprod, t, x_start.shape, offsets) * x_start\n",
    "            + _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape, offsets)\n",
    "            * noise\n",
    "        )\n",
    "\n",
    "        if mask == None:\n",
    "            return x_t\n",
    "        else:\n",
    "            mask = th.broadcast_to(mask.unsqueeze(dim=-1), x_start.shape)\n",
    "            return th.where(mask==0, x_start, x_t)\n",
    "\n",
    "    def q_posterior_mean_variance(self, x_start, x_t, t, offsets):\n",
    "        \"\"\"\n",
    "        Compute the mean and variance of the diffusion posterior: \n",
    "            q(x_{t-1} | x_t, x_0)\n",
    "\n",
    "        \"\"\"\n",
    "        assert x_start.shape == x_t.shape\n",
    "        posterior_mean = (\n",
    "            _extract_into_tensor(self.posterior_mean_coef1, t, x_t.shape, offsets) * x_start\n",
    "            + _extract_into_tensor(self.posterior_mean_coef2, t, x_t.shape, offsets) * x_t\n",
    "        )\n",
    "        posterior_variance = _extract_into_tensor(self.posterior_variance, t, x_t.shape, offsets)\n",
    "        posterior_log_variance_clipped = _extract_into_tensor(\n",
    "            self.posterior_log_variance_clipped, t, x_t.shape, offsets\n",
    "        )\n",
    "        assert (\n",
    "            posterior_mean.shape[0]\n",
    "            == posterior_variance.shape[0]\n",
    "            == posterior_log_variance_clipped.shape[0]\n",
    "            == x_start.shape[0]\n",
    "        )\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(\n",
    "        self, model, x, t, offsets, clip_denoised=True, denoised_fn=None, model_kwargs=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Apply the model to get p(x_{t-1} | x_t), as well as a prediction of\n",
    "        the initial x, x_0.\n",
    "\n",
    "        :param model: the model, which takes a signal and a batch of timesteps\n",
    "                      as input.\n",
    "        :param x: the [N x C x ...] tensor at time t.\n",
    "        :param t: a 1-D Tensor of timesteps.\n",
    "        :param clip_denoised: if True, clip the denoised signal into [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample. Applies before\n",
    "            clip_denoised.\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :return: a dict with the following keys:\n",
    "                 - 'mean': the model mean output.\n",
    "                 - 'variance': the model variance output.\n",
    "                 - 'log_variance': the log of 'variance'.\n",
    "                 - 'pred_xstart': the prediction for x_0.\n",
    "        \"\"\"\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = {}\n",
    "\n",
    "        B, C = x.size(0), x.size(-1)\n",
    "        assert t.shape == (B,)\n",
    "        model_output = model(x, self._scale_timesteps(t), **model_kwargs)\n",
    "        \n",
    "        # for fixedlarge, we set the initial (log-)variance like so\n",
    "        # to get a better decoder log likelihood.\n",
    "        model_variance = np.insert(self.betas, 1, self.posterior_variance[:, 1], axis=1)[:, 1:]\n",
    "        model_log_variance = np.log(model_variance)\n",
    "        \n",
    "        model_variance = _extract_into_tensor(model_variance, t, x.shape, offsets)\n",
    "        model_log_variance = _extract_into_tensor(model_log_variance, t, x.shape, offsets)\n",
    "\n",
    "        def process_xstart(x):\n",
    "            if denoised_fn is not None:\n",
    "                x = denoised_fn(x, t)\n",
    "            if clip_denoised:\n",
    "                return x.clamp(-1, 1)\n",
    "            return x\n",
    "\n",
    "        if self.predict_xstart:\n",
    "            # knn rounding -> using most close token as input, and get new emb output\n",
    "            pred_xstart = process_xstart(model_output)\n",
    "        else:\n",
    "            ### model is used to predict eps\n",
    "            pred_xstart = process_xstart(\n",
    "                self._predict_xstart_from_eps(x_t=x, t=t, offsets=offsets, eps=model_output)\n",
    "            )\n",
    "\n",
    "        # Î¼_t\n",
    "        model_mean, _, _ = self.q_posterior_mean_variance(\n",
    "            x_start=pred_xstart, x_t=x, t=t, offsets=offsets\n",
    "        )\n",
    "\n",
    "        assert (\n",
    "            model_mean.shape == model_log_variance.shape == pred_xstart.shape == x.shape\n",
    "        )\n",
    "        return {\n",
    "            \"mean\": model_mean,\n",
    "            \"variance\": model_variance,\n",
    "            \"log_variance\": model_log_variance,\n",
    "            \"pred_xstart\": pred_xstart,\n",
    "        }\n",
    "\n",
    "    def p_sample(\n",
    "        self, model, x, t, offsets, clip_denoised=True, denoised_fn=None, model_kwargs=None,\n",
    "            top_p=None, mask=None, x_start=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Sample x_{t-1} from the model at the given timestep.\n",
    "\n",
    "        :param model: the model to sample from.\n",
    "        :param x: the current tensor at x_{t-1}.\n",
    "        :param t: the value of t, starting at 0 for the first diffusion step.\n",
    "        :param clip_denoised: if True, clip the x_start prediction to [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample.\n",
    "        :param mask: anchoring masked position to x_start\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :return: a dict containing the following keys:\n",
    "                 - 'sample': a random sample from the model.\n",
    "                 - 'pred_xstart': a prediction of x_0.\n",
    "        \"\"\"\n",
    "        out = self.p_mean_variance(\n",
    "            model,\n",
    "            x,\n",
    "            t,\n",
    "            offsets,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "        )\n",
    "        if top_p is not None and top_p > 0:\n",
    "            # print('top_p sampling')\n",
    "            noise = th.randn_like(x)\n",
    "            replace_mask = th.abs(noise) > top_p\n",
    "            while replace_mask.any():\n",
    "                noise[replace_mask] = th.randn_like(noise[replace_mask])\n",
    "                replace_mask = th.abs(noise) > top_p\n",
    "            assert (th.abs(noise) <= top_p).all()\n",
    "\n",
    "        else:\n",
    "            noise = th.randn_like(x)\n",
    "\n",
    "        nonzero_mask = (\n",
    "            (t != 0).float().view(-1, *([1] * (len(x.shape) - 1)))\n",
    "        )  # no noise when t == 0\n",
    "        # get new sample from mean and variance \n",
    "        sample = out[\"mean\"] + nonzero_mask * th.exp(0.5 * out[\"log_variance\"]) * noise\n",
    "        if mask == None:\n",
    "            pass\n",
    "        else:\n",
    "            # only denoise y, x keep use x0\n",
    "            sample = th.where(mask==0, x_start, sample)\n",
    "\n",
    "        return {\n",
    "            \"sample\": sample, \n",
    "            \"pred_xstart\": out[\"pred_xstart\"], # after knn rounding model output\n",
    "            \"greedy_mean\": out[\"mean\"], \n",
    "            \"out\": out\n",
    "        }\n",
    "\n",
    "    \n",
    "    def p_sample_loop(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        offsets,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        top_p=None,\n",
    "        clamp_step=None,\n",
    "        clamp_first=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "        gap=1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate samples from the model.\n",
    "\n",
    "        :param model: the model module.\n",
    "        :param shape: the shape of the samples, (N, C, H, W).\n",
    "        :param noise: if specified, the noise from the encoder to sample.\n",
    "                      Should be of the same shape as `shape`.\n",
    "        :param clip_denoised: if True, clip x_start predictions to [-1, 1].\n",
    "        :param denoised_fn: if not None, a function which applies to the\n",
    "            x_start prediction before it is used to sample.\n",
    "        :param mask: anchoring masked position to x_start\n",
    "        :param clamp_step: in clamp_first mode, choose end clamp step, otherwise starting clamp step\n",
    "        :param clamp_first: bool, clamp_first mode\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :param device: if specified, the device to create the samples on.\n",
    "                       If not specified, use a model parameter's device.\n",
    "        :param progress: if True, show a tqdm progress bar.\n",
    "        :return: a non-differentiable batch of samples.\n",
    "        \"\"\"\n",
    "        final = []\n",
    "        for sample in self.p_sample_loop_progressive(\n",
    "            model,\n",
    "            shape,\n",
    "            offsets,\n",
    "            noise=noise,\n",
    "            clip_denoised=clip_denoised,\n",
    "            denoised_fn=denoised_fn,\n",
    "            model_kwargs=model_kwargs,\n",
    "            device=device,\n",
    "            progress=progress,\n",
    "            top_p=top_p,\n",
    "            clamp_step=clamp_step,\n",
    "            clamp_first=clamp_first,\n",
    "            mask=mask,\n",
    "            x_start=x_start\n",
    "        ):\n",
    "            final.append(sample['sample'].tolist())\n",
    "        return final\n",
    "\n",
    "    def p_sample_loop_progressive(\n",
    "        self,\n",
    "        model,\n",
    "        shape,\n",
    "        offsets,\n",
    "        noise=None,\n",
    "        clip_denoised=True,\n",
    "        denoised_fn=None,\n",
    "        model_kwargs=None,\n",
    "        device=None,\n",
    "        progress=False,\n",
    "        top_p=None,\n",
    "        clamp_step=None,\n",
    "        clamp_first=None,\n",
    "        mask=None,\n",
    "        x_start=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Generate samples from the model and yield intermediate samples from\n",
    "        each timestep of diffusion.\n",
    "\n",
    "        Arguments are the same as p_sample_loop().\n",
    "        Returns a generator over dicts, where each dict is the return value of\n",
    "        p_sample().\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = next(model.parameters()).device\n",
    "        assert isinstance(shape, (tuple, list))\n",
    "        if noise is not None: # custom your the start point of x_0\n",
    "            sample_x = noise # mask x\n",
    "        else:\n",
    "            sample_x = th.randn(*shape, device=device)\n",
    "        indices = list(range(self.num_timesteps))[::-1]\n",
    "\n",
    "        if progress:\n",
    "            # Lazy import so that we don't depend on tqdm.\n",
    "            from tqdm.auto import tqdm\n",
    "            indices = tqdm(indices)\n",
    "\n",
    "        for i in indices: # from T to 0\n",
    "            t = th.tensor([i] * shape[0], device=device)\n",
    "            if not clamp_first:\n",
    "                if i > clamp_step:\n",
    "                    denoised_fn_cur = None\n",
    "                else:\n",
    "                    denoised_fn_cur = denoised_fn\n",
    "            else:\n",
    "                if i >= clamp_step:\n",
    "                    denoised_fn_cur = denoised_fn\n",
    "                else:\n",
    "                    denoised_fn_cur = None\n",
    "            with th.no_grad():\n",
    "                out = self.p_sample(\n",
    "                    model,\n",
    "                    sample_x,\n",
    "                    t,\n",
    "                    offsets,\n",
    "                    clip_denoised=clip_denoised,\n",
    "                    denoised_fn=denoised_fn_cur,\n",
    "                    model_kwargs=model_kwargs,\n",
    "                    top_p=top_p,\n",
    "                    mask=mask,\n",
    "                    x_start=x_start\n",
    "                )\n",
    "                if i == 0:\n",
    "                    yield out\n",
    "                sample_x = out[\"sample\"]\n",
    "\n",
    "\n",
    "    def _get_x_start(self, x_start_mean, std):\n",
    "        '''\n",
    "        Word embedding projection from {Emb(w)} to {x_0}\n",
    "        :param x_start_mean: word embedding\n",
    "        :return: x_0\n",
    "        '''\n",
    "        noise = th.randn_like(x_start_mean)\n",
    "        assert noise.shape == x_start_mean.shape\n",
    "        return (\n",
    "             x_start_mean + std * noise\n",
    "        )\n",
    "\n",
    "    def _token_discrete_loss(self, x_t, get_logits, input_ids, mask=None, truncate=False, t=None):\n",
    "        '''\n",
    "        the loss of -log p(w|z_0)\n",
    "        :param x_start_mean: word embedding\n",
    "        :return: x_0\n",
    "        '''\n",
    "        reshaped_x_t = x_t\n",
    "        logits = get_logits(reshaped_x_t)\n",
    "        loss_fct = th.nn.CrossEntropyLoss(reduction='none')\n",
    "        decoder_nll = loss_fct(logits.view(-1, logits.size(-1)), input_ids.view(-1)).view(input_ids.shape)\n",
    "        if mask != None:\n",
    "            decoder_nll *= mask # only y\n",
    "        if mask != None:\n",
    "            decoder_nll = decoder_nll.sum(dim=-1)/mask.sum(dim=-1) # each y mean nll loss\n",
    "        else:\n",
    "            decoder_nll = decoder_nll.mean(dim=-1) # each sentence mean nll loss\n",
    "\n",
    "        return decoder_nll\n",
    "\n",
    "    def _x0_helper(self, model_output, x, t, offsets):\n",
    "\n",
    "        if self.predict_xstart:\n",
    "            pred_xstart = model_output\n",
    "            # pred_prev -> q(x_{t-1} | x_t, x_0) mean\n",
    "            pred_prev, _, _ = self.q_posterior_mean_variance(\n",
    "                x_start=pred_xstart, x_t=x, t=t, offsets=offsets\n",
    "            )\n",
    "\n",
    "        else: # predict eps\n",
    "            pred_xstart = self._predict_xstart_from_eps(x_t=x, t=t, offsets=offsets, eps=model_output)\n",
    "        \n",
    "            pred_prev, _, _ = self.q_posterior_mean_variance(\n",
    "                x_start=pred_xstart, x_t=x, t=t, offsets=offsets\n",
    "            )\n",
    "\n",
    "        return {'pred_xprev':pred_prev, 'pred_xstart':pred_xstart}\n",
    "\n",
    "    def training_losses_seq2seq(self, model, x_start, t, offsets, ids, mask, noise=None):\n",
    "        \"\"\"\n",
    "        Compute training losses for a single timestep.\n",
    "\n",
    "        :param model: the model to evaluate loss on.\n",
    "        :param x_start: the [N x C x ...] tensor of inputs. # not used unless fixing the input embeddings\n",
    "        :param t: a batch of timestep indices.\n",
    "        :param ids: from origial model_kwargs dict\n",
    "        :param mask: from origial model_kwargs dict\n",
    "        :param model_kwargs: if not None, a dict of extra keyword arguments to\n",
    "            pass to the model. This can be used for conditioning.\n",
    "        :param noise: if specified, the specific Gaussian noise to try to remove.\n",
    "        :return: a dict with the key \"loss\" containing a tensor of shape [N].\n",
    "                 Some mean or variance settings may also have other keys.\n",
    "        \"\"\"\n",
    "        x_start_fix = x_start\n",
    "        input_ids_x = ids\n",
    "        input_ids_mask = mask\n",
    "        \n",
    "        x_start_mean = model.model.module.get_embeds(input_ids_x)\n",
    "        \n",
    "        std = _extract_into_tensor(self.sqrt_one_minus_alphas_cumprod,\n",
    "                                   th.tensor([0]*input_ids_x.shape[0]).to(x_start_mean.device),\n",
    "                                   x_start_mean.shape,\n",
    "                                   offsets)\n",
    "\n",
    "        x_start = self._get_x_start(x_start_mean, std)\n",
    "        if noise is None:\n",
    "            noise = th.randn_like(x_start)\n",
    "\n",
    "        x_t = self.q_sample(x_start, t, offsets, noise=noise, mask=input_ids_mask)\n",
    "        \n",
    "        get_logits = model.model.module.get_logits\n",
    "\n",
    "        terms = {}\n",
    "\n",
    "        target = x_start\n",
    "        model_output = model(x_t, self._scale_timesteps(t))\n",
    "        assert model_output.shape == target.shape == x_start.shape\n",
    "        terms[\"mse\"] = mean_flat((target - model_output) ** 2)\n",
    "        \n",
    "        model_out_x_start = self._x0_helper(model_output, x_t, t, offsets)['pred_xstart'] # predicted_xstart = model_output\n",
    "        t0_mask = (t == 0)\n",
    "        t0_loss = mean_flat((x_start_mean - model_out_x_start) ** 2)\n",
    "        terms[\"mse\"] = th.where(t0_mask, t0_loss, terms[\"mse\"])\n",
    "\n",
    "        out_mean, _, _ = self.q_mean_variance(x_start, th.LongTensor([self.num_timesteps - 1]*input_ids_x.shape[0]).to(x_start.device), offsets)\n",
    "        tT_loss =  mean_flat(out_mean ** 2)\n",
    "        \n",
    "        decoder_nll = self._token_discrete_loss(x_start, get_logits, input_ids_x) # embedding regularization\n",
    "        terms[\"nll\"] = self._token_discrete_loss(model_out_x_start, get_logits, input_ids_x, mask=input_ids_mask, truncate=True, t=t) # x_0->model_out_x_start\n",
    "        \n",
    "        terms[\"loss\"] = terms[\"mse\"] + decoder_nll + tT_loss\n",
    "\n",
    "        return terms\n",
    "\n",
    "def _extract_into_tensor(arr, timesteps, broadcast_shape, offsets):\n",
    "    \"\"\"\n",
    "    Extract values from a 1-D numpy array for a batch of indices.\n",
    "\n",
    "    :param arr: the 1-D numpy array.\n",
    "    :param timesteps: a tensor of indices into the array to extract.\n",
    "    :param broadcast_shape: a larger shape of K dimensions with the batch\n",
    "                            dimension equal to the length of timesteps.\n",
    "    :return: a tensor of shape [batch_size, 1, ...] where the shape has K dims.\n",
    "    \"\"\"\n",
    "    start_index = offsets*timesteps.shape[0]\n",
    "    res = th.tensor([arr[start_index+i][timesteps[i]] for i in range(timesteps.shape[0])]).float().to(device=timesteps.device)\n",
    "    while len(res.shape) < len(broadcast_shape):\n",
    "        res = res[..., None]\n",
    "    return res.expand(broadcast_shape)\n",
    "\n",
    "\n",
    "def space_timesteps(num_timesteps, section_counts):\n",
    "    \"\"\"\n",
    "    Create a list of timesteps to use from an original diffusion process,\n",
    "    given the number of timesteps we want to take from equally-sized portions\n",
    "    of the original process.\n",
    "\n",
    "    For example, if there's 300 timesteps and the section counts are [10,15,20]\n",
    "    then the first 100 timesteps are strided to be 10 timesteps, the second 100\n",
    "    are strided to be 15 timesteps, and the final 100 are strided to be 20.\n",
    "\n",
    "    If the stride is a string starting with \"ddim\", then the fixed striding\n",
    "    from the DDIM paper is used, and only one section is allowed.\n",
    "\n",
    "    :param num_timesteps: the number of diffusion steps in the original\n",
    "                          process to divide up.\n",
    "    :param section_counts: either a list of numbers, or a string containing\n",
    "                           comma-separated numbers, indicating the step count\n",
    "                           per section. As a special case, use \"ddimN\" where N\n",
    "                           is a number of steps to use the striding from the\n",
    "                           DDIM paper.\n",
    "    :return: a set of diffusion steps from the original process to use.\n",
    "    \"\"\"\n",
    "    if isinstance(section_counts, str):\n",
    "        if section_counts.startswith(\"ddim\"):\n",
    "            desired_count = int(section_counts[len(\"ddim\") :])\n",
    "            for i in range(1, num_timesteps):\n",
    "                if len(range(0, num_timesteps, i)) == desired_count:\n",
    "                    return set(range(0, num_timesteps, i))\n",
    "            raise ValueError(\n",
    "                f\"cannot create exactly {num_timesteps} steps with an integer stride\"\n",
    "            )\n",
    "        section_counts = [int(x) for x in section_counts.split(\",\")]\n",
    "    size_per = num_timesteps // len(section_counts)\n",
    "    extra = num_timesteps % len(section_counts)\n",
    "    start_idx = 0\n",
    "    all_steps = []\n",
    "    for i, section_count in enumerate(section_counts):\n",
    "        size = size_per + (1 if i < extra else 0)\n",
    "        if size < section_count:\n",
    "            raise ValueError(\n",
    "                f\"cannot divide section of {size} steps into {section_count}\"\n",
    "            )\n",
    "        if section_count <= 1:\n",
    "            frac_stride = 1\n",
    "        else:\n",
    "            frac_stride = (size - 1) / (section_count - 1)\n",
    "        cur_idx = 0.0\n",
    "        taken_steps = []\n",
    "        for _ in range(section_count):\n",
    "            taken_steps.append(start_idx + round(cur_idx))\n",
    "            cur_idx += frac_stride\n",
    "        all_steps += taken_steps\n",
    "        start_idx += size\n",
    "    return set(all_steps)\n",
    "\n",
    "\n",
    "class SpacedDiffusion(GaussianDiffusion):\n",
    "    \"\"\"\n",
    "    A diffusion process which can skip steps in a base diffusion process.\n",
    "\n",
    "    :param use_timesteps: a collection (sequence or set) of timesteps from the\n",
    "                          original diffusion process to retain.\n",
    "    :param kwargs: the kwargs to create the base diffusion process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_timesteps, **kwargs):\n",
    "        self.use_timesteps = set(use_timesteps)\n",
    "        self.timestep_map = []\n",
    "        self.original_num_steps = kwargs[\"betas\"].shape[1]\n",
    "\n",
    "        base_diffusion = GaussianDiffusion(**kwargs) \n",
    "        last_alpha_cumprod = 1.0\n",
    "        new_betas = []\n",
    "        for i in range(kwargs['betas'].shape[1]):\n",
    "            if i in self.use_timesteps:\n",
    "                new_betas.append(1 - base_diffusion.alphas_cumprod[:, i] / last_alpha_cumprod)\n",
    "                last_alpha_cumprod = base_diffusion.alphas_cumprod[:, i]\n",
    "                self.timestep_map.append(i)\n",
    "        kwargs[\"betas\"] = np.transpose(np.array(new_betas))\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def p_mean_variance(\n",
    "        self, model, *args, **kwargs\n",
    "    ):  # pylint: disable=signature-differs\n",
    "        # print('called p_mean_var')\n",
    "        return super().p_mean_variance(self._wrap_model(model), *args, **kwargs)\n",
    "\n",
    "    def training_losses(\n",
    "        self, model, *args, **kwargs\n",
    "    ):  # pylint: disable=signature-differs\n",
    "        # print('called training_losses')\n",
    "        return super().training_losses(self._wrap_model(model), *args, **kwargs)\n",
    "\n",
    "    def _wrap_model(self, model):\n",
    "        if isinstance(model, _WrappedModel):\n",
    "            return model\n",
    "        return _WrappedModel(\n",
    "            model, self.timestep_map, self.rescale_timesteps, self.original_num_steps\n",
    "        )\n",
    "\n",
    "    def _scale_timesteps(self, t):\n",
    "        # Scaling is done by the wrapped model.\n",
    "        return t\n",
    "    \n",
    "    def get_sqrt_alphas_cumprod(self):\n",
    "        return super().get_sqrt_alphas_cumprod()\n",
    "\n",
    "\n",
    "class _WrappedModel:\n",
    "    def __init__(self, model, timestep_map, rescale_timesteps, original_num_steps):\n",
    "        self.model = model\n",
    "        self.timestep_map = timestep_map\n",
    "        self.rescale_timesteps = rescale_timesteps\n",
    "        self.original_num_steps = original_num_steps\n",
    "\n",
    "    def __call__(self, x, ts, **kwargs):\n",
    "        map_tensor = th.tensor(self.timestep_map, device=ts.device, dtype=ts.dtype)\n",
    "        new_ts = map_tensor[ts]\n",
    "        if self.rescale_timesteps:\n",
    "            new_ts = new_ts.float() * (1000.0 / self.original_num_steps)\n",
    "        return self.model(x, new_ts, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54585aa4",
   "metadata": {},
   "source": [
    "### transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be9bf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    The full Transformer model with attention and timestep embedding.\n",
    "\n",
    "    :param input_dims: dims of the input Tensor.\n",
    "    :param output_dims: dims of the output Tensor.\n",
    "    :param hidden_t_dim: dims of time embedding.\n",
    "    :param dropout: the dropout probability.\n",
    "    :param config/config_name: the config of PLMs.\n",
    "    :param init_pretrained: bool, init whole network params with PLMs.\n",
    "    :param vocab_size: the size of vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dims,\n",
    "        output_dims,\n",
    "        hidden_t_dim,\n",
    "        dropout=0,\n",
    "        config=None,\n",
    "        config_name='bert-base-uncased',\n",
    "        vocab_size=None,\n",
    "        init_pretrained='no',\n",
    "        logits_mode=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if config is None:\n",
    "            config = AutoConfig.from_pretrained(config_name)\n",
    "            config.hidden_dropout_prob = dropout\n",
    "\n",
    "        self.input_dims = input_dims\n",
    "        self.hidden_t_dim = hidden_t_dim\n",
    "        self.output_dims = output_dims\n",
    "        self.dropout = dropout\n",
    "        self.logits_mode = logits_mode\n",
    "        self.hidden_size = config.hidden_size\n",
    "\n",
    "        self.word_embedding = nn.Embedding(vocab_size, self.input_dims)\n",
    "        self.lm_head = nn.Linear(self.input_dims, vocab_size)\n",
    "        with th.no_grad():\n",
    "            self.lm_head.weight = self.word_embedding.weight\n",
    "\n",
    "        time_embed_dim = hidden_t_dim * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            linear(hidden_t_dim, time_embed_dim),\n",
    "            SiLU(),\n",
    "            linear(time_embed_dim, config.hidden_size),\n",
    "        )\n",
    "        \n",
    "        if self.input_dims != config.hidden_size:\n",
    "            self.input_up_proj = nn.Sequential(nn.Linear(input_dims, config.hidden_size),\n",
    "                                              nn.Tanh(), nn.Linear(config.hidden_size, config.hidden_size))\n",
    "        \n",
    "        if init_pretrained == 'bert':\n",
    "            print('initializing from pretrained bert...')\n",
    "            print(config)\n",
    "            temp_bert = BertModel.from_pretrained(config_name, config=config)\n",
    "\n",
    "            self.word_embedding = temp_bert.embeddings.word_embeddings\n",
    "            with th.no_grad():\n",
    "                self.lm_head.weight = self.word_embedding.weight\n",
    "            \n",
    "            self.input_transformers = temp_bert.encoder\n",
    "            self.register_buffer(\"position_ids\", th.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "            self.position_embeddings = temp_bert.embeddings.position_embeddings\n",
    "            self.LayerNorm = temp_bert.embeddings.LayerNorm\n",
    "\n",
    "            del temp_bert.embeddings\n",
    "            del temp_bert.pooler\n",
    "\n",
    "        elif init_pretrained == 'no':\n",
    "            self.input_transformers = BertEncoder(config)\n",
    "\n",
    "            self.register_buffer(\"position_ids\", th.arange(config.max_position_embeddings).expand((1, -1)))\n",
    "            self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
    "            self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        \n",
    "        else:\n",
    "            assert False, \"invalid type of init_pretrained\"\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "        if self.output_dims != config.hidden_size:\n",
    "            self.output_down_proj = nn.Sequential(nn.Linear(config.hidden_size, config.hidden_size),\n",
    "                                                nn.Tanh(), nn.Linear(config.hidden_size, self.output_dims))\n",
    "\n",
    "    def get_embeds(self, input_ids):\n",
    "        return self.word_embedding(input_ids)\n",
    "\n",
    "    def get_logits(self, hidden_repr):\n",
    "        if self.logits_mode == 1:\n",
    "            return self.lm_head(hidden_repr)\n",
    "        elif self.logits_mode == 2:\n",
    "            text_emb = hidden_repr\n",
    "            emb_norm = (self.lm_head.weight ** 2).sum(-1).view(-1, 1)\n",
    "            text_emb_t = th.transpose(text_emb.view(-1, text_emb.size(-1)), 0, 1)\n",
    "            arr_norm = (text_emb ** 2).sum(-1).view(-1, 1)\n",
    "            dist = emb_norm + arr_norm.transpose(0, 1) - 2.0 * th.mm(self.lm_head.weight,\n",
    "                                                                     text_emb_t)\n",
    "            scores = th.sqrt(th.clamp(dist, 0.0, np.inf)).view(emb_norm.size(0), hidden_repr.size(0),\n",
    "                                                               hidden_repr.size(1))\n",
    "            scores = -scores.permute(1, 2, 0).contiguous()\n",
    "            return scores\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "    def forward(self, x, timesteps):\n",
    "        \"\"\"\n",
    "        Apply the model to an input batch.\n",
    "\n",
    "        :param x: an [N x C x ...] Tensor of inputs.\n",
    "        :param timesteps: a 1-D batch of timesteps.\n",
    "        :return: an [N x C x ...] Tensor of outputs.\n",
    "        \"\"\"\n",
    "        emb_t = self.time_embed(timestep_embedding(timesteps, self.hidden_t_dim))\n",
    "\n",
    "        if self.input_dims != self.hidden_size:\n",
    "            emb_x = self.input_up_proj(x)\n",
    "        else:\n",
    "            emb_x = x\n",
    "\n",
    "        seq_length = x.size(1)\n",
    "        position_ids = self.position_ids[:, : seq_length ]\n",
    "        emb_inputs = self.position_embeddings(position_ids) + emb_x + emb_t.unsqueeze(1).expand(-1, seq_length, -1)\n",
    "        emb_inputs = self.dropout(self.LayerNorm(emb_inputs))\n",
    "\n",
    "        input_trans_hidden_states = self.input_transformers(emb_inputs).last_hidden_state\n",
    "        \n",
    "        if self.output_dims != self.hidden_size:\n",
    "            h = self.output_down_proj(input_trans_hidden_states)\n",
    "        else:\n",
    "            h = input_trans_hidden_states\n",
    "        h = h.type(x.dtype)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f53eee",
   "metadata": {},
   "source": [
    "### step_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8444e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_named_schedule_sampler(name, diffusion):\n",
    "    \"\"\"\n",
    "    Create a ScheduleSampler from a library of pre-defined samplers.\n",
    "\n",
    "    :param name: the name of the sampler.\n",
    "    :param diffusion: the diffusion object to sample for.\n",
    "    \"\"\"\n",
    "    if name == \"uniform\":\n",
    "        return UniformSampler(diffusion)\n",
    "    elif name == \"lossaware\":\n",
    "        return LossSecondMomentResampler(diffusion)\n",
    "    elif name == \"fixstep\":\n",
    "        return FixSampler(diffusion)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown schedule sampler: {name}\")\n",
    "\n",
    "\n",
    "class ScheduleSampler(ABC):\n",
    "    \"\"\"\n",
    "    A distribution over timesteps in the diffusion process, intended to reduce\n",
    "    variance of the objective.\n",
    "\n",
    "    By default, samplers perform unbiased importance sampling, in which the\n",
    "    objective's mean is unchanged.\n",
    "    However, subclasses may override sample() to change how the resampled\n",
    "    terms are reweighted, allowing for actual changes in the objective.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def weights(self):\n",
    "        \"\"\"\n",
    "        Get a numpy array of weights, one per diffusion step.\n",
    "\n",
    "        The weights needn't be normalized, but must be positive.\n",
    "        \"\"\"\n",
    "\n",
    "    def sample(self, batch_size, device):\n",
    "        \"\"\"\n",
    "        Importance-sample timesteps for a batch. #(from diffuseq p.4)\n",
    "\n",
    "        :param batch_size: the number of timesteps.\n",
    "        :param device: the torch device to save to.\n",
    "        :return: a tuple (timesteps, weights):\n",
    "                 - timesteps: a tensor of timestep indices.\n",
    "                 - weights: a tensor of weights to scale the resulting losses.\n",
    "        \"\"\"\n",
    "        w = self.weights()\n",
    "        p = w / np.sum(w)\n",
    "        indices_np = np.random.choice(len(p), size=(batch_size,), p=p)\n",
    "        indices = th.from_numpy(indices_np).long().to(device)\n",
    "        weights_np = 1 / (len(p) * p[indices_np])\n",
    "        weights = th.from_numpy(weights_np).float().to(device)\n",
    "        return indices, weights\n",
    "\n",
    "\n",
    "class UniformSampler(ScheduleSampler):\n",
    "    def __init__(self, diffusion_steps):\n",
    "        self.diffusion = diffusion_steps\n",
    "        self._weights = np.ones([diffusion_steps])\n",
    "\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "class FixSampler(ScheduleSampler):\n",
    "    def __init__(self, diffusion_steps):\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "\n",
    "        ###############################################################\n",
    "        ### You can custome your own sampling weight of steps here. ###\n",
    "        ###############################################################\n",
    "        self._weights = np.concatenate([np.ones([diffusion_steps//2]), np.zeros([diffusion_steps//2]) + 0.5])\n",
    "\n",
    "    def weights(self):\n",
    "        return self._weights\n",
    "\n",
    "\n",
    "class LossAwareSampler(ScheduleSampler):\n",
    "    def update_with_local_losses(self, local_ts, local_losses):\n",
    "        \"\"\"\n",
    "        Update the reweighting using losses from a model.\n",
    "\n",
    "        Call this method from each rank with a batch of timesteps and the\n",
    "        corresponding losses for each of those timesteps.\n",
    "        This method will perform synchronization to make sure all of the ranks\n",
    "        maintain the exact same reweighting.\n",
    "\n",
    "        :param local_ts: an integer Tensor of timesteps.\n",
    "        :param local_losses: a 1D Tensor of losses.\n",
    "        \"\"\"\n",
    "        batch_sizes = [\n",
    "            th.tensor([0], dtype=th.int32, device=local_ts.device)\n",
    "            for _ in range(dist.get_world_size())\n",
    "        ]\n",
    "        dist.all_gather(\n",
    "            batch_sizes,\n",
    "            th.tensor([len(local_ts)], dtype=th.int32, device=local_ts.device),\n",
    "        )\n",
    "\n",
    "        # Pad all_gather batches to be the maximum batch size.\n",
    "        batch_sizes = [x.item() for x in batch_sizes]\n",
    "        max_bs = max(batch_sizes)\n",
    "        timestep_batches = [th.zeros(max_bs).to(local_ts) for bs in batch_sizes]\n",
    "        loss_batches = [th.zeros(max_bs).to(local_losses) for bs in batch_sizes]\n",
    "        dist.all_gather(timestep_batches, local_ts)\n",
    "        dist.all_gather(loss_batches, local_losses)\n",
    "        timesteps = [\n",
    "            x.item() for y, bs in zip(timestep_batches, batch_sizes) for x in y[:bs]\n",
    "        ]\n",
    "        losses = [x.item() for y, bs in zip(loss_batches, batch_sizes) for x in y[:bs]]\n",
    "        self.update_with_all_losses(timesteps, losses)\n",
    "        \n",
    "        del batch_sizes, max_bs, timestep_batches, loss_batches, timesteps, losses\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_with_all_losses(self, ts, losses):\n",
    "        \"\"\"\n",
    "        Update the reweighting using losses from a model.\n",
    "\n",
    "        Sub-classes should override this method to update the reweighting\n",
    "        using losses from the model.\n",
    "\n",
    "        This method directly updates the reweighting without synchronizing\n",
    "        between workers. It is called by update_with_local_losses from all\n",
    "        ranks with identical arguments. Thus, it should have deterministic\n",
    "        behavior to maintain state across workers.\n",
    "\n",
    "        :param ts: a list of int timesteps.\n",
    "        :param losses: a list of float losses, one per timestep.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class LossSecondMomentResampler(LossAwareSampler):\n",
    "    def __init__(self, diffusion_steps, history_per_term=10, uniform_prob=0.001):\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.history_per_term = history_per_term\n",
    "        self.uniform_prob = uniform_prob\n",
    "        self._loss_history = np.zeros(\n",
    "            [diffusion_steps, history_per_term], dtype=np.float64\n",
    "        )\n",
    "        self._loss_counts = np.zeros([diffusion_steps], dtype=np.int64)\n",
    "\n",
    "    def weights(self):\n",
    "        if not self._warmed_up():\n",
    "            return np.ones([self.diffusion_steps], dtype=np.float64)\n",
    "        weights = np.sqrt(np.mean(self._loss_history ** 2, axis=-1))\n",
    "        weights /= np.sum(weights)\n",
    "        weights *= 1 - self.uniform_prob\n",
    "        weights += self.uniform_prob / len(weights)\n",
    "        return weights\n",
    "\n",
    "    def update_with_all_losses(self, ts, losses):\n",
    "        for t, loss in zip(ts, losses):\n",
    "            if self._loss_counts[t] == self.history_per_term:\n",
    "                # Shift out the oldest loss term.\n",
    "                self._loss_history[t, :-1] = self._loss_history[t, 1:]\n",
    "                self._loss_history[t, -1] = loss\n",
    "            else:\n",
    "                self._loss_history[t, self._loss_counts[t]] = loss\n",
    "                self._loss_counts[t] += 1\n",
    "\n",
    "    def _warmed_up(self):\n",
    "        return (self._loss_counts == self.history_per_term).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f5615",
   "metadata": {},
   "source": [
    "### Model B  (Encoder-Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404d331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True) \n",
    "        \n",
    "    def forward(self, input_sentences):\n",
    "        self.lstm.flatten_parameters()\n",
    "        embedded = self.embedding(input_sentences)\n",
    "        encoder_output, (encoder_h, encoder_c) = self.lstm(embedded)\n",
    "        return encoder_output, encoder_h, encoder_c\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size+1, embedding_dim) # output_size+1 -> T/F + BOS\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, input_instructions, encoder_h, encoder_c):\n",
    "        self.lstm.flatten_parameters()\n",
    "        embedded = self.embedding(input_instructions)\n",
    "        decoder_output, (decoder_h, decoder_c) = self.lstm(embedded, (encoder_h, encoder_c))\n",
    "        output = self.linear(decoder_output)\n",
    "        output = self.softmax(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9eeb0",
   "metadata": {},
   "source": [
    "### other functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da229ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_file(filename):\n",
    "    with open(f'{checkpoint_path}/{filename}.csv', 'w' , newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "def write_log(msg):\n",
    "    with open(f'{checkpoint_path}/training_log.csv', 'a' , newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([msg])\n",
    "        \n",
    "def write_time_usage(msg):\n",
    "    with open(f'{checkpoint_path}/time_usage.csv', 'a' , newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([msg])\n",
    "        \n",
    "def record_information(checkpoint_path, msg, filename):\n",
    "    with open(f'{checkpoint_path}/{filename}.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([msg])\n",
    "        \n",
    "def sample_sentence(data, mask, num, N, seed = None):\n",
    "    idx_list = []\n",
    "    if seed != None:\n",
    "        random.seed(seed)\n",
    "    while(len(idx_list) < ((num-1) // N + 1)):\n",
    "        idx = random.randint(0, len(data)-1)\n",
    "        if idx not in idx_list: idx_list.append(idx)\n",
    "    batch_data = th.tensor([data[idx] for idx in idx_list for _ in range(N)])[:num]\n",
    "    batch_mask = th.tensor([mask[idx] for idx in idx_list for _ in range(N)])[:num]\n",
    "    return batch_data, batch_mask, idx_list\n",
    "\n",
    "def get_standard_betas(diffusion_steps, noise_schedule):\n",
    "    if noise_schedule == 'linear':\n",
    "        scale = 1000 / diffusion_steps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return np.linspace(beta_start, beta_end, diffusion_steps, dtype=np.float64)\n",
    "    elif noise_schedule == 'sqrt':\n",
    "        return betas_for_alpha_bar(diffusion_steps, lambda t: 1-np.sqrt(t + 0.0001),)\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return np.array(betas)\n",
    "\n",
    "def calculate_my_betas(beta_ins, standard_betas):\n",
    "    betas = list()\n",
    "    for i in range(len(beta_ins)):\n",
    "        point = 0\n",
    "        now = 0\n",
    "        standard_betas_copy = standard_betas.copy()\n",
    "        beta_temp = [standard_betas_copy[point]]\n",
    "        point += 1\n",
    "        now = point\n",
    "        for instruction in beta_ins[i]:\n",
    "            if instruction: \n",
    "                beta_temp.append(standard_betas_copy[point])\n",
    "                now = point\n",
    "            else: \n",
    "                beta_temp.append(standard_betas_copy[now])\n",
    "            point += 1\n",
    "        betas.append(beta_temp)\n",
    "    betas = th.tensor(betas)\n",
    "    return betas\n",
    "\n",
    "def _scale_timesteps(t, rescale_timesteps, num_timesteps):\n",
    "    if rescale_timesteps:\n",
    "        return t.float() * (1000.0 / num_timesteps)\n",
    "    return t\n",
    "\n",
    "def modelB_inference(batch_data, encoder, decoder, diffusion_steps, word2idx, mode, weight):\n",
    "    s_t = time.time()\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    TF_weight = th.tensor([(1+weight), (1-weight)]).to(dev())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        encoder_output, encoder_h, encoder_c = encoder(batch_data.to(dev()))\n",
    "\n",
    "        decoder_input = th.tensor([[word2idx['BOS']]*(diffusion_steps-1) for _ in range(batch_data.shape[0])])\n",
    "        decoder_input = decoder_input.to(dev())\n",
    "\n",
    "        inference_data = th.tensor([[word2idx['F']]*(diffusion_steps-1) for _ in range(decoder_input.shape[0])])\n",
    "        for step in range(diffusion_steps-1):\n",
    "            decoder_output = decoder(decoder_input, encoder_h, encoder_c)\n",
    "            decoder_output = decoder_output[:,step,]\n",
    "            decoder_output = decoder_output * TF_weight\n",
    "            if mode == 'argmax':\n",
    "                decoder_output_TF = th.argmax(decoder_output, dim=1)\n",
    "            elif mode == 'multinomial':\n",
    "                decoder_output_TF = th.multinomial(decoder_output, 1)\n",
    "                decoder_output_TF = decoder_output_TF[:,0]\n",
    "\n",
    "            inference_data[:, step] = decoder_output_TF\n",
    "            if step+1 < diffusion_steps-1:\n",
    "                decoder_input[:,step+1] = decoder_output_TF\n",
    "            del decoder_output, decoder_output_TF\n",
    "        del encoder_output, encoder_h, encoder_c, decoder_input\n",
    "    e_t = time.time() - s_t\n",
    "    write_time_usage(f'[Model B Inference] batch:{batch_data.shape[0]}. Using {e_t/60:.2f} mins.')\n",
    "    return inference_data\n",
    "\n",
    "def get_loss_reward(\n",
    "    betas, \n",
    "    data, \n",
    "    mask, \n",
    "    model, \n",
    "    diffusion_steps,\n",
    "    t,\n",
    "    offsets,\n",
    "    timestep_respacing, \n",
    "    rescale_timesteps,\n",
    "    predict_xstart,\n",
    "    learn_sigma,\n",
    "    use_kl,\n",
    "    rescale_learned_sigmas,\n",
    "):\n",
    "    s_t = time.time()\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        # create diffusion with betas\n",
    "        if not timestep_respacing:\n",
    "            timestep_respacing = [diffusion_steps]\n",
    "\n",
    "        diffusion = SpacedDiffusion(\n",
    "            use_timesteps=space_timesteps(diffusion_steps, timestep_respacing),\n",
    "            betas=betas,\n",
    "            rescale_timesteps=rescale_timesteps,\n",
    "            predict_xstart=predict_xstart,\n",
    "            learn_sigmas = learn_sigma,\n",
    "            sigma_small = sigma_small,\n",
    "            use_kl = use_kl,\n",
    "            rescale_learned_sigmas=rescale_learned_sigmas\n",
    "        )\n",
    "\n",
    "        # get q sample with each diffusion_steps\n",
    "        x_start_mean = model.module.get_embeds(data) # shape -> (batch_size, seq_len, hidden_dim)\n",
    "        std = _extract_into_tensor(\n",
    "            diffusion.sqrt_one_minus_alphas_cumprod,\n",
    "            th.tensor([0]*x_start_mean.shape[0]).to(x_start_mean.device),\n",
    "            x_start_mean.shape,\n",
    "            offsets,\n",
    "        ).to(dev())\n",
    "\n",
    "        x_start_q = diffusion._get_x_start(x_start_mean, std) # shape -> (batch_size, seq_len, hidden_dim)\n",
    "        q_mask = mask\n",
    "\n",
    "        noise = th.randn_like(x_start_q)\n",
    "\n",
    "        \n",
    "        # calculate each diffusion_steps loss\n",
    "        target = x_start_q\n",
    "        \n",
    "        reward_loss = []\n",
    "        q = diffusion.q_sample(x_start_q, t, offsets, noise=noise, mask=q_mask).to(dev())\n",
    "        model_output = model(q, _scale_timesteps(t, rescale_timesteps, diffusion_steps))\n",
    "\n",
    "        mse = mean_flat((target - model_output) ** 2)\n",
    "\n",
    "        t0_mask = (t == 0)\n",
    "        t0_loss = mean_flat((x_start_mean - model_output) ** 2)\n",
    "        mse = th.where(t0_mask, t0_loss, mse)\n",
    "        \n",
    "        mse = 1.0 / mse\n",
    "\n",
    "        reward_loss.append(mse.tolist())\n",
    "\n",
    "        reward_loss = th.tensor(reward_loss)\n",
    "        # shape: (diffusion_steps, batch) -> (batch, diffusion_steps)\n",
    "        reward_loss = th.transpose(reward_loss, 0, 1)\n",
    "    e_t = time.time() - s_t\n",
    "    write_time_usage(f'[Get loss reward] batch:{data.shape[0]}. Using {e_t/60:.2f} mins.')\n",
    "    return reward_loss\n",
    "\n",
    "def save_model(model, model_name, master_params, step = None):\n",
    "    if step == None:\n",
    "        filename = f'model/{model_name}.pt'\n",
    "    else:\n",
    "        filename = f'model/{model_name}_{step}.pt'\n",
    "    state_dict = model.state_dict()\n",
    "    for i, (name, _value) in enumerate(model.named_parameters()):\n",
    "        assert name in state_dict\n",
    "        state_dict[name] = master_params[i]\n",
    "    msg = 'writing to', bf.join(checkpoint_path, filename)\n",
    "    write_log(msg)\n",
    "    with bf.BlobFile(bf.join(checkpoint_path, filename), \"wb\") as f: # DEBUG **\n",
    "        th.save(state_dict, f)\n",
    "        \n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=index,memory.used --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    return memory_free_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9b955",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b833fb",
   "metadata": {},
   "source": [
    "## tokenizer and model_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3540ba04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /tmp/openai-2024-04-25-18-04-52-293796\n",
      "seed: 102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_dist() # Setup a distributed process group. \n",
    "logger.configure()\n",
    "\n",
    "print(f'seed: {seed}')\n",
    "set_seed(seed)\n",
    "\n",
    "tokenizer, vocab_size = load_tokenizer(config_name, checkpoint_path, vocab)\n",
    "model_weight = load_model_emb(vocab_size, hidden_dim, checkpoint_path)\n",
    "model_weight.to(dev())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffba1e7",
   "metadata": {},
   "source": [
    "## initial hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4047fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "micro_batch_size_B = 1024\n",
    "micro_batch_size_D = 64\n",
    "\n",
    "update_D_loop = 100\n",
    "update_D_count = 0\n",
    "\n",
    "weight = 0 # Rsparse choose T/F distribution * weight => å¸æè½å¤é¸ä¸äºF\n",
    "\n",
    "exploration = 1\n",
    "epochs = 80000\n",
    "save_interval = 1000\n",
    "\n",
    "name2val = float(0)\n",
    "name2cnt = int(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fee93b",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca4a818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## \n",
      "Loading text data...\n",
      "############################## \n",
      "Loading dataset Wiki from ./datasets/Wiki...\n",
      "### Loading form the TRAIN set...\n",
      "### Data samples...\n",
      " ['Grantham was released in 1977, having served 10 years.', 'Leslie Michael Grantham (30 April 1947 â 15 June 2018) was an English actor, best known for his role as \"Dirty\" Den Watts in the BBC soap opera \"EastEnders\".'] ['He was released from prison in 1977.', 'He is best known for playing Den Watts in \"EastEnders\" from 1985-1989 and from 2003-2005.']\n",
      "RAM used: 4603.23 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function helper_tokenize.<locals>.tokenize_function at 0x7fcb4b73c8b0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['src', 'trg'],\n",
      "    num_rows: 677751\n",
      "})\n",
      "RAM used: 4791.45 MB\n",
      "     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ff55d90c36481e9a2d17f06cecefc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset #0:   0%|          | 0/170 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7db4bcbad924702a93c013f4a08dfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset #1:   0%|          | 0/170 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b71b8656a364b6ba5b2777a9bf0099f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset #2:   0%|          | 0/170 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840acccd71c34e26ba455877b24204c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset #3:   0%|          | 0/170 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tokenized_datasets Dataset({\n",
      "    features: ['input_id_x', 'input_id_y'],\n",
      "    num_rows: 677751\n",
      "})\n",
      "### tokenized_datasets...example [101, 3946, 3511, 2001, 2207, 1999, 3355, 1010, 2383, 2366, 2184, 2086, 1012, 102]\n",
      "RAM used: 5121.69 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3572b60b7d204df28623c8ad2cecde97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merge and mask:   0%|          | 0/678 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM used: 5732.21 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5596a05e414a56b76984a30d557c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "padding:   0%|          | 0/678 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_id_x', 'input_id_y', 'input_ids', 'input_mask'],\n",
      "    num_rows: 677751\n",
      "}) padded dataset\n",
      "RAM used: 7020.01 MB\n",
      "RAM used: 6874.36 MB\n"
     ]
    }
   ],
   "source": [
    "data = load_data_text(\n",
    "batch_size=batch_size,\n",
    "seq_len=seq_len,\n",
    "dataset = dataset,\n",
    "data_dir = data_dir,\n",
    "loaded_vocab=tokenizer,\n",
    "model_emb=model_weight # use model's weights as init\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f855c15",
   "metadata": {},
   "source": [
    "## initial model $B_\\phi$ (encoder-decoder), model $f_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acecdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {\n",
    "    'F': 0,\n",
    "    'T': 1,\n",
    "    'BOS': 2,\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5cfb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "output_size = 2 # T/F\n",
    "encoder_embedding_dim = 64\n",
    "decoder_embedding_dim = 64\n",
    "encoder_hidden_dim = 64\n",
    "decoder_hidden_dim = 64\n",
    "\n",
    "encoder = Encoder(input_size, encoder_embedding_dim, encoder_hidden_dim).to(dev())\n",
    "decoder = Decoder(output_size, decoder_embedding_dim, decoder_hidden_dim).to(dev())\n",
    "\n",
    "encoder_params = copy.deepcopy(list(encoder.parameters()))\n",
    "decoder_params = copy.deepcopy(list(decoder.parameters()))\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder_params)\n",
    "decoder_optimizer = optim.Adam(decoder_params)\n",
    "criterion = nn.NLLLoss(reduction = 'none')\n",
    "\n",
    "# DP\n",
    "encoder_DP = th.nn.DataParallel(encoder)\n",
    "decoder_DP = th.nn.DataParallel(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cebcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta schedule\n",
    "standard_betas = get_standard_betas(diffusion_steps, noise_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "441140df",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelD = TransformerNetModel(\n",
    "    input_dims=hidden_dim,\n",
    "    output_dims=(hidden_dim if not learn_sigma else hidden_dim*2),\n",
    "    hidden_t_dim=hidden_t_dim,\n",
    "    dropout=dropout,\n",
    "    config_name=config_name,\n",
    "    vocab_size=vocab_size,\n",
    "    init_pretrained=use_plm_init\n",
    ")\n",
    "modelD.to(dev())\n",
    "\n",
    "model_weight.to(dev())\n",
    "\n",
    "schedule_sampler = create_named_schedule_sampler(schedule_sampler_name, diffusion_steps)\n",
    "\n",
    "master_params = list(modelD.parameters())\n",
    "ema_params = copy.deepcopy(master_params)\n",
    "optimizer = AdamW(master_params, lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# DP\n",
    "modelD_DP = th.nn.DataParallel(modelD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3716c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial log file\n",
    "log_file_name = [\n",
    "    'time_usage',\n",
    "    'training_log',\n",
    "    'meta_rewards',\n",
    "    'train_x_beta_ins',\n",
    "]\n",
    "for filename in log_file_name: create_log_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef4434",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a862dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'Epoch {epoch+1} / {epochs}')\n",
    "    write_log(f'Epoch {epoch+1} / {epochs}')\n",
    "\n",
    "    batch_hidden, batch = next(data)\n",
    "    batch_hidden = batch_hidden.to(dev())\n",
    "    batch_data = batch['input_ids']\n",
    "    batch_mask = batch['input_mask']\n",
    "    batch_data_x = batch_data * (1 - batch_mask) # only x mask y\n",
    "\n",
    "    # R base\n",
    "    if epoch % update_D_loop == 0:\n",
    "        beta_ins = modelB_inference(batch_data_x, encoder_DP, decoder_DP, diffusion_steps, word2idx, 'multinomial', weight)\n",
    "        betas = calculate_my_betas(beta_ins, standard_betas)            \n",
    "        t, weights = schedule_sampler.sample(batch_data.shape[0], dev())\n",
    "\n",
    "        reward_base = get_loss_reward(\n",
    "            betas, \n",
    "            batch_data.to(dev()), \n",
    "            batch_mask.to(dev()),\n",
    "            modelD_DP,\n",
    "            diffusion_steps,\n",
    "            t,\n",
    "            0, # offsets\n",
    "            timestep_respacing, \n",
    "            rescale_timesteps,\n",
    "            predict_xstart,\n",
    "            learn_sigma,\n",
    "            use_kl,\n",
    "            rescale_learned_sigmas,\n",
    "        )\n",
    "\n",
    "    # update model D\n",
    "    if epoch % update_D_loop != 99:\n",
    "        beta_ins = modelB_inference(batch_data_x, encoder_DP, decoder_DP, diffusion_steps, word2idx, 'multinomial', weight)\n",
    "        betas = calculate_my_betas(beta_ins, standard_betas)\n",
    "\n",
    "        # diffusion\n",
    "        if not timestep_respacing:\n",
    "            timestep_respacing = [diffusion_steps]\n",
    "\n",
    "        diffusion = SpacedDiffusion(\n",
    "            use_timesteps=space_timesteps(diffusion_steps, timestep_respacing),\n",
    "            betas=betas,\n",
    "            rescale_timesteps=rescale_timesteps,\n",
    "            predict_xstart=predict_xstart,\n",
    "            learn_sigmas = learn_sigma,\n",
    "            sigma_small = sigma_small,\n",
    "            use_kl = use_kl,\n",
    "            rescale_learned_sigmas=rescale_learned_sigmas\n",
    "        )\n",
    "\n",
    "        # calculate lossD\n",
    "        modelD_DP.train()\n",
    "        zero_grad(master_params)\n",
    "\n",
    "        loop = ((batch_data.shape[0]-1) // micro_batch_size_D)+1\n",
    "        for i in range(loop):\n",
    "            t, weights = schedule_sampler.sample(batch_hidden[i*micro_batch_size_D:(i+1)*micro_batch_size_D].shape[0], dev())\n",
    "\n",
    "            compute_losses = functools.partial(\n",
    "                diffusion.training_losses,\n",
    "                modelD_DP,\n",
    "                batch_hidden[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "                t.to(dev()),\n",
    "                i, # offset\n",
    "                batch_data[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "                batch_mask[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "            )\n",
    "\n",
    "            losses = compute_losses()\n",
    "\n",
    "            if isinstance(schedule_sampler, LossAwareSampler):\n",
    "                schedule_sampler.update_with_local_losses(\n",
    "                    t, losses[\"loss\"].detach()\n",
    "                )\n",
    "\n",
    "            loss = losses['loss'] * weights\n",
    "            loss= loss.mean()\n",
    "\n",
    "\n",
    "            # output loss calculate\n",
    "            if not th.isnan(loss):\n",
    "                name2val = name2val * name2cnt / (name2cnt + 1) + loss.item() / (name2cnt + 1)\n",
    "                name2cnt = name2cnt + 1\n",
    "            else:\n",
    "                write_log(f'[Warning] loss nan')\n",
    "\n",
    "            loss.backward()\n",
    "            del losses, loss, t, weights\n",
    "        # _anneal_lr\n",
    "        frac_done = (epoch + 1) / epochs\n",
    "        lr = learning_rate * (1 - frac_done)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        # update model D\n",
    "        optimizer.step()\n",
    "        # update ema_params\n",
    "        update_ema(ema_params, master_params, rate=ema_rate)\n",
    "        write_log(f'[Model D] loss: {name2val:.4f}')\n",
    "\n",
    "    else: # Meta\n",
    "        betas_ins_list = list()\n",
    "        betas_list = list()\n",
    "        for e in range(exploration):\n",
    "            write_log(f'[Exploration 1] {e+1} / {exploration}')\n",
    "            beta_ins = modelB_inference(batch_data_x, encoder_DP, decoder_DP, diffusion_steps, word2idx, 'multinomial', weight)\n",
    "            betas = calculate_my_betas(beta_ins, standard_betas)\n",
    "            betas_ins_list.append(beta_ins)\n",
    "            betas_list.append(betas)\n",
    "\n",
    "            # record beta\n",
    "            if e == 0:\n",
    "                msg = f'{batch_data_x[:10].tolist(), beta_ins[:10].tolist()}'\n",
    "                record_information(checkpoint_path, msg, 'train_x_beta_ins')\n",
    "\n",
    "            # diffusion\n",
    "            if not timestep_respacing:\n",
    "                timestep_respacing = [diffusion_steps]\n",
    "\n",
    "            diffusion = SpacedDiffusion(\n",
    "                use_timesteps=space_timesteps(diffusion_steps, timestep_respacing),\n",
    "                betas=betas,\n",
    "                rescale_timesteps=rescale_timesteps,\n",
    "                predict_xstart=predict_xstart,\n",
    "                learn_sigmas = learn_sigma,\n",
    "                sigma_small = sigma_small,\n",
    "                use_kl = use_kl,\n",
    "                rescale_learned_sigmas=rescale_learned_sigmas\n",
    "            )\n",
    "\n",
    "            # calculate lossD\n",
    "            modelD_DP.train()\n",
    "            zero_grad(master_params)\n",
    "\n",
    "            loop = ((batch_data.shape[0]-1) // micro_batch_size_D)+1\n",
    "            for i in range(loop):\n",
    "                t, weights = schedule_sampler.sample(batch_hidden[i*micro_batch_size_D:(i+1)*micro_batch_size_D].shape[0], dev())\n",
    "\n",
    "                compute_losses = functools.partial(\n",
    "                    diffusion.training_losses,\n",
    "                    modelD_DP,\n",
    "                    batch_hidden[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "                    t.to(dev()),\n",
    "                    i, # offsets\n",
    "                    batch_data[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "                    batch_mask[i*micro_batch_size_D:(i+1)*micro_batch_size_D].to(dev()),\n",
    "                )\n",
    "\n",
    "                losses = compute_losses()\n",
    "\n",
    "                if isinstance(schedule_sampler, LossAwareSampler):\n",
    "                    schedule_sampler.update_with_local_losses(\n",
    "                        t, losses[\"loss\"].detach()\n",
    "                    )\n",
    "\n",
    "                loss = losses['loss'] * weights\n",
    "                loss= loss.mean()\n",
    "\n",
    "                # output loss calculate\n",
    "                if not th.isnan(loss):\n",
    "                    name2val = name2val * name2cnt / (name2cnt + 1) + loss.item() / (name2cnt + 1)\n",
    "                    name2cnt = name2cnt + 1\n",
    "                else:\n",
    "                    write_log(f'[Warning] loss nan')\n",
    "\n",
    "                loss.backward()\n",
    "                del losses, loss, t, weights\n",
    "\n",
    "        # _anneal_lr\n",
    "        frac_done = (epoch + 1) / epochs\n",
    "        lr = learning_rate * (1 - frac_done)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "        # update model D\n",
    "        optimizer.step()\n",
    "        # update ema_params\n",
    "        update_ema(ema_params, master_params, rate=ema_rate)\n",
    "        write_log(f'[Model D exploration] loss: {name2val:.4f}')\n",
    "\n",
    "        lossB = 0\n",
    "        for e in range(exploration):\n",
    "            write_log(f'[Exploration 2] {e+1} / {exploration}')\n",
    "            t, weights = schedule_sampler.sample(batch_data.shape[0], dev())\n",
    "            reward = get_loss_reward(\n",
    "                betas_list[e], \n",
    "                batch_data.to(dev()), \n",
    "                batch_mask.to(dev()),\n",
    "                modelD_DP,\n",
    "                diffusion_steps,\n",
    "                t,\n",
    "                0, # offets\n",
    "                timestep_respacing, \n",
    "                rescale_timesteps,\n",
    "                predict_xstart,\n",
    "                learn_sigma,\n",
    "                use_kl,\n",
    "                rescale_learned_sigmas,\n",
    "            )\n",
    "\n",
    "            meta_reward = (reward - reward_base).to(dev())\n",
    "            meta_reward = meta_reward[:,0]*weights\n",
    "\n",
    "            meta_reward = th.where(meta_reward>=0, 1, -1)\n",
    "\n",
    "            # record meta reward\n",
    "            if e == 0:\n",
    "                msg = f'{meta_reward[:10].tolist()}'\n",
    "                record_information(checkpoint_path, msg, 'meta_rewards')\n",
    "\n",
    "            meta_rewards = th.zeros(len(batch_data), diffusion_steps)\n",
    "            meta_rewards[i][t[i]] = meta_reward[i]\n",
    "\n",
    "            # calculate lossB\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            encoder_DP.train()\n",
    "            decoder_DP.train()\n",
    "\n",
    "            loss = 0\n",
    "            loop = ((batch_data.shape[0]-1) // micro_batch_size_B)+1\n",
    "            for i in range(loop):\n",
    "                encoder_output, encoder_h, encoder_c = encoder_DP(batch_data_x[i*micro_batch_size_B:(i+1)*micro_batch_size_B].to(dev()))\n",
    "                decoder_input = th.cat((th.tensor([[word2idx['BOS']]] * len(betas_ins_list[e][i*micro_batch_size_B:(i+1)*micro_batch_size_B])), betas_ins_list[e][i*micro_batch_size_B:(i+1)*micro_batch_size_B]), dim=1)\n",
    "                decoder_output = decoder_DP(decoder_input.to(dev()), encoder_h, encoder_c)\n",
    "                decoder_output = th.log(decoder_output)\n",
    "                for j in range(decoder_output.shape[0]):\n",
    "                    loss += criterion(decoder_output[j][:-1], betas_ins_list[e][i*micro_batch_size_B:(i+1)*micro_batch_size_B][j].to(dev()))*meta_rewards[i*micro_batch_size_B:(i+1)*micro_batch_size_B][j, :-1].to(dev())\n",
    "            loss = th.sum(loss)\n",
    "            lossB += loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "        # update model B\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        write_log(f'[Model B exploration] loss: {lossB / exploration:.4f}')\n",
    "\n",
    "    update_D_count = (update_D_count + 1) % update_D_loop\n",
    "\n",
    "    memory_usage = get_gpu_memory()\n",
    "    write_log(f'[Memory] Memory usage: {memory_usage}')\n",
    "    write_log(f'[Memory] CPU memory usage: {psutil.virtual_memory()[3] / (1024**3):.6f} G')\n",
    "\n",
    "    if (epoch+1) % save_interval == 0:\n",
    "        write_log(f'[Save] Save model D intervally.')\n",
    "        save_model(encoder, 'encoder', encoder_params, epoch+1)\n",
    "        save_model(decoder, 'decoder', decoder_params, epoch+1)\n",
    "        save_model(modelD, 'modelD', master_params, epoch+1)\n",
    "        save_model(modelD, 'modelD_ema', ema_params, epoch+1)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    write_log(f'[Elapsed time] {elapsed_time:.4f} secs.')\n",
    "    del batch_hidden, batch, batch_data, batch_mask\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138663c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
